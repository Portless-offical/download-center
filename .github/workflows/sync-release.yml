# yaml-language-server: $schema=https://json.schemastore.org/github-workflow.json
name: Sync Releases from R2

on:
  workflow_dispatch:
    inputs:
      version:
        description: 'Version to sync (leave empty for latest)'
        required: false
        type: string
        default: ''
      sync_all:
        description: 'Sync all versions from R2'
        required: false
        default: false
        type: boolean
      dry_run:
        description: 'Dry run - do not create releases or push changes'
        required: false
        default: false
        type: boolean
      force_overwrite:
        description: 'Force overwrite existing releases'
        required: false
        default: false
        type: boolean

  schedule:
    # Run daily at 2 AM UTC to check for new releases
    - cron: '0 2 * * *'

permissions:
  contents: write

env:
  AWS_MAX_ATTEMPTS: 3
  AWS_RETRY_MODE: adaptive

# Prevent concurrent runs to avoid race conditions
concurrency:
  group: sync-releases-${{ github.ref }}
  cancel-in-progress: false

jobs:
  # ============================================================================
  # Job 1: Validate configuration and detect versions to sync
  # ============================================================================
  prepare:
    name: Prepare Sync
    runs-on: ubuntu-22.04
    timeout-minutes: 10
    outputs:
      versions_json: ${{ steps.detect.outputs.versions_json }}
      versions_count: ${{ steps.detect.outputs.versions_count }}
      should_sync: ${{ steps.detect.outputs.should_sync }}
      latest_version: ${{ steps.detect.outputs.latest_version }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          fetch-depth: 0

      - name: Validate R2 Configuration
        id: validate
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
          R2_ENDPOINT_URL: ${{ secrets.R2_ENDPOINT_URL }}
          R2_BUCKET_NAME: ${{ secrets.R2_BUCKET_NAME }}
        run: |
          set -euo pipefail

          echo "::group::Validating R2 Configuration"

          # Validate required secrets
          VALIDATION_FAILED=false
          for VAR_NAME in AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY R2_ENDPOINT_URL R2_BUCKET_NAME; do
            if [[ -z "${!VAR_NAME:-}" ]]; then
              echo "::error::${VAR_NAME} is not set"
              VALIDATION_FAILED=true
            else
              echo "✓ ${VAR_NAME} is set (length: ${#!VAR_NAME})"
            fi
          done

          if [[ "$VALIDATION_FAILED" == "true" ]]; then
            exit 1
          fi

          # Validate endpoint URL format
          if [[ ! "$R2_ENDPOINT_URL" =~ ^https?:// ]]; then
            echo "::error::R2_ENDPOINT_URL must start with http:// or https://"
            exit 1
          fi

          echo "✓ All configuration validated"
          echo "::endgroup::"

          # Test connection
          echo "::group::Testing R2 Connection"
          if aws s3 ls "s3://${R2_BUCKET_NAME}" \
            --endpoint-url "${R2_ENDPOINT_URL}" \
            --region auto &>/dev/null; then
            echo "✓ Successfully connected to R2 bucket: ${R2_BUCKET_NAME}"
          else
            echo "::error::Failed to connect to R2 bucket"
            echo "Please verify your R2 credentials and configuration"
            exit 1
          fi
          echo "::endgroup::"

      - name: Detect versions to sync
        id: detect
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
          R2_ENDPOINT_URL: ${{ secrets.R2_ENDPOINT_URL }}
          R2_BUCKET_NAME: ${{ secrets.R2_BUCKET_NAME }}
          INPUT_VERSION: ${{ inputs.version }}
          SYNC_ALL: ${{ inputs.sync_all }}
        run: |
          set -euo pipefail

          echo "::group::Detecting Versions to Sync"

          # Function to get all versions from R2
          get_all_versions() {
            aws s3api list-objects-v2 \
              --bucket "${R2_BUCKET_NAME}" \
              --prefix "releases/" \
              --delimiter "/" \
              --endpoint-url "${R2_ENDPOINT_URL}" \
              --region auto \
              --query 'CommonPrefixes[].Prefix' \
              --output text 2>/dev/null \
              | tr '\t' '\n' \
              | sed 's|releases/||g; s|/$||g' \
              | grep -v '^$' \
              | sort -V \
              || true
          }

          # Function to get latest version
          get_latest_version() {
            if aws s3api head-object \
              --bucket "${R2_BUCKET_NAME}" \
              --key "releases/latest.json" \
              --endpoint-url "${R2_ENDPOINT_URL}" \
              --region auto &>/dev/null; then

              aws s3 cp "s3://${R2_BUCKET_NAME}/releases/latest.json" /tmp/latest.json \
                --endpoint-url "${R2_ENDPOINT_URL}" \
                --region auto \
                --only-show-errors

              jq -r '.version // empty' /tmp/latest.json 2>/dev/null || true
            fi
          }

          # Determine which versions to sync
          VERSIONS_ARRAY=()

          if [[ "${SYNC_ALL}" == "true" ]]; then
            echo "Mode: Sync all versions"
            while IFS= read -r version; do
              [[ -n "$version" ]] && VERSIONS_ARRAY+=("$version")
            done < <(get_all_versions)

          elif [[ -n "${INPUT_VERSION}" ]]; then
            echo "Mode: Specific version - ${INPUT_VERSION}"
            VERSIONS_ARRAY+=("${INPUT_VERSION}")

          else
            echo "Mode: Latest version"
            LATEST=$(get_latest_version)

            if [[ -z "$LATEST" ]]; then
              echo "latest.json not found, detecting from directory listing..."
              LATEST=$(get_all_versions | tail -1)
            fi

            if [[ -n "$LATEST" ]]; then
              VERSIONS_ARRAY+=("$LATEST")
            fi
          fi

          # Output results
          if [[ ${#VERSIONS_ARRAY[@]} -eq 0 ]]; then
            echo "::warning::No versions found to sync"
            echo "should_sync=false" >> "$GITHUB_OUTPUT"
            echo "versions_count=0" >> "$GITHUB_OUTPUT"
            echo "versions_json=[]" >> "$GITHUB_OUTPUT"
            echo "latest_version=" >> "$GITHUB_OUTPUT"
          else
            echo "Found ${#VERSIONS_ARRAY[@]} version(s) to sync:"
            printf '  - %s\n' "${VERSIONS_ARRAY[@]}"

            # Convert to JSON array for matrix
            VERSIONS_JSON=$(printf '%s\n' "${VERSIONS_ARRAY[@]}" | jq -R . | jq -sc .)

            echo "should_sync=true" >> "$GITHUB_OUTPUT"
            echo "versions_count=${#VERSIONS_ARRAY[@]}" >> "$GITHUB_OUTPUT"
            echo "versions_json=${VERSIONS_JSON}" >> "$GITHUB_OUTPUT"
            echo "latest_version=${VERSIONS_ARRAY[-1]}" >> "$GITHUB_OUTPUT"
          fi

          echo "::endgroup::"

      - name: Summary
        run: |
          cat >> $GITHUB_STEP_SUMMARY << EOF
          ## Sync Preparation Summary

          | Parameter | Value |
          |-----------|-------|
          | Should Sync | ${{ steps.detect.outputs.should_sync }} |
          | Versions Count | ${{ steps.detect.outputs.versions_count }} |
          | Latest Version | ${{ steps.detect.outputs.latest_version }} |
          | Dry Run | ${{ inputs.dry_run }} |
          EOF

  # ============================================================================
  # Job 2: Download and process each version (matrix job)
  # ============================================================================
  sync:
    name: Sync ${{ matrix.version }}
    needs: prepare
    if: needs.prepare.outputs.should_sync == 'true'
    runs-on: ubuntu-22.04
    timeout-minutes: 30
    strategy:
      fail-fast: false
      max-parallel: 3
      matrix:
        version: ${{ fromJson(needs.prepare.outputs.versions_json) }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2

      - name: Download release artifacts from R2
        id: download
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
          R2_ENDPOINT_URL: ${{ secrets.R2_ENDPOINT_URL }}
          R2_BUCKET_NAME: ${{ secrets.R2_BUCKET_NAME }}
          VERSION: ${{ matrix.version }}
        run: |
          set -euo pipefail

          RELEASE_DIR="binaries/${VERSION}"
          mkdir -p "${RELEASE_DIR}"

          echo "::group::Downloading artifacts for ${VERSION}"

          # List all files in the version directory
          aws s3api list-objects-v2 \
            --bucket "${R2_BUCKET_NAME}" \
            --prefix "releases/${VERSION}/" \
            --endpoint-url "${R2_ENDPOINT_URL}" \
            --region auto \
            --output json > /tmp/r2_listing.json

          # Check if any files exist
          FILE_COUNT=$(jq -r '.Contents | length // 0' /tmp/r2_listing.json)
          echo "Found ${FILE_COUNT} objects in R2"

          if [[ "$FILE_COUNT" -eq 0 ]]; then
            echo "::warning::No files found for version ${VERSION}"
            echo "download_count=0" >> "$GITHUB_OUTPUT"
            echo "::endgroup::"
            exit 0
          fi

          # Download files
          DOWNLOADED=0
          FAILED=0
          SKIPPED=0

          for KEY in $(jq -r '.Contents[].Key // empty' /tmp/r2_listing.json); do
            FILENAME=$(basename "$KEY")
            [[ -z "$FILENAME" ]] && continue

            # Skip metadata files
            if [[ "$FILENAME" =~ \.(json|txt|md|sig|sha256)$ ]]; then
              echo "⊘ Skipping metadata: $FILENAME"
              ((SKIPPED++))
              continue
            fi

            SIZE=$(jq -r --arg key "$KEY" '.Contents[] | select(.Key == $key) | .Size // 0' /tmp/r2_listing.json)
            SIZE_MB=$(echo "scale=1; $SIZE / 1048576" | bc)

            echo "↓ Downloading ${FILENAME} (${SIZE_MB} MB)..."

            if aws s3 cp "s3://${R2_BUCKET_NAME}/${KEY}" "${RELEASE_DIR}/${FILENAME}" \
              --endpoint-url "${R2_ENDPOINT_URL}" \
              --region auto \
              --only-show-errors; then
              echo "  ✓ Downloaded ${FILENAME}"
              ((DOWNLOADED++))
            else
              echo "  ✗ Failed to download ${FILENAME}"
              ((FAILED++))
            fi
          done

          echo ""
          echo "Download Summary: ${DOWNLOADED} downloaded, ${FAILED} failed, ${SKIPPED} skipped"

          echo "download_count=${DOWNLOADED}" >> "$GITHUB_OUTPUT"
          echo "failed_count=${FAILED}" >> "$GITHUB_OUTPUT"

          echo "::endgroup::"

          if [[ "$FAILED" -gt 0 ]]; then
            echo "::warning::${FAILED} file(s) failed to download"
          fi

      - name: Generate manifest
        id: manifest
        env:
          VERSION: ${{ matrix.version }}
          R2_PUBLIC_URL: ${{ secrets.R2_PUBLIC_URL }}
        run: |
          set -euo pipefail

          RELEASE_DIR="binaries/${VERSION}"

          echo "::group::Generating manifest for ${VERSION}"

          python3 << 'PYTHON_SCRIPT'
          import json
          import os
          import hashlib
          from pathlib import Path
          from datetime import datetime, timezone

          version = os.environ['VERSION']
          public_url = os.environ.get('R2_PUBLIC_URL', '').rstrip('/')
          release_dir = Path(f"binaries/{version}")

          def detect_platform(filename: str) -> dict:
              filename_lower = filename.lower()
              info = {'os': 'unknown', 'arch': 'unknown', 'format': 'unknown'}

              # Detect OS
              if '.dmg' in filename_lower or 'darwin' in filename_lower or 'macos' in filename_lower:
                  info['os'] = 'darwin'
              elif '.appimage' in filename_lower or '.deb' in filename_lower or '.rpm' in filename_lower or 'linux' in filename_lower:
                  info['os'] = 'linux'
              elif '.msi' in filename_lower or '.exe' in filename_lower or 'windows' in filename_lower or 'win' in filename_lower:
                  info['os'] = 'windows'

              # Detect architecture
              if 'arm64' in filename_lower or 'aarch64' in filename_lower:
                  info['arch'] = 'arm64'
              elif 'x64' in filename_lower or 'x86_64' in filename_lower or 'amd64' in filename_lower:
                  info['arch'] = 'x64'
              elif 'x86' in filename_lower or 'i386' in filename_lower or 'i686' in filename_lower:
                  info['arch'] = 'x86'
              elif 'universal' in filename_lower:
                  info['arch'] = 'universal'

              # Detect format
              for ext, fmt in [('.dmg', 'dmg'), ('.appimage', 'appimage'), ('.deb', 'deb'),
                               ('.rpm', 'rpm'), ('.msi', 'msi'), ('.exe', 'exe'),
                               ('.tar.gz', 'tar.gz'), ('.zip', 'zip')]:
                  if filename_lower.endswith(ext):
                      info['format'] = fmt
                      break

              return info

          def sha256_file(filepath: Path) -> str:
              h = hashlib.sha256()
              with open(filepath, 'rb') as f:
                  for chunk in iter(lambda: f.read(8192), b''):
                      h.update(chunk)
              return h.hexdigest()

          assets = []
          for filepath in sorted(release_dir.glob('*')):
              if not filepath.is_file() or filepath.name == 'manifest.json':
                  continue

              size = filepath.stat().st_size
              platform = detect_platform(filepath.name)
              url = f"{public_url}/releases/{version}/{filepath.name}" if public_url else f"releases/{version}/{filepath.name}"

              asset = {
                  'filename': filepath.name,
                  'size': size,
                  'size_human': f"{size / (1024*1024):.1f} MB",
                  'sha256': sha256_file(filepath),
                  'platform': platform['os'],
                  'arch': platform['arch'],
                  'format': platform['format'],
                  'url': url
              }
              assets.append(asset)
              print(f"✓ {filepath.name} ({asset['size_human']}) - {platform['os']}/{platform['arch']}")

          manifest = {
              'version': version,
              'released_at': datetime.now(timezone.utc).isoformat(),
              'asset_count': len(assets),
              'assets': assets,
              'platforms': list(set(a['platform'] for a in assets if a['platform'] != 'unknown')),
              'formats': list(set(a['format'] for a in assets if a['format'] != 'unknown'))
          }

          (release_dir / 'manifest.json').write_text(json.dumps(manifest, indent=2))
          print(f"\n✓ Generated manifest with {len(assets)} assets")

          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
              f.write(f"asset_count={len(assets)}\n")
          PYTHON_SCRIPT

          echo "::endgroup::"

      - name: Verify downloads
        run: |
          RELEASE_DIR="binaries/${{ matrix.version }}"
          echo "::group::Downloaded files"
          if [[ -d "$RELEASE_DIR" ]]; then
            echo "Files in $RELEASE_DIR:"
            ls -lh "$RELEASE_DIR/" || echo "Directory is empty"
            echo ""
            echo "Total size: $(du -sh "$RELEASE_DIR" | cut -f1)"
          else
            echo "::warning::Release directory not found: $RELEASE_DIR"
          fi
          echo "::endgroup::"

      - name: Upload artifacts
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2
        with:
          name: release-${{ matrix.version }}
          path: binaries/${{ matrix.version }}/
          retention-days: 7
          if-no-files-found: warn

  # ============================================================================
  # Job 3: Commit changes and create GitHub releases
  # ============================================================================
  publish:
    name: Publish Releases
    needs: [prepare, sync]
    runs-on: ubuntu-22.04
    timeout-minutes: 15
    if: success() && inputs.dry_run != true

    steps:
      - name: Checkout repository
        uses: actions/checkout@11bd71901bbe5b1630ceea73d27597364c9af683 # v4.2.2
        with:
          fetch-depth: 0

      - name: Download all artifacts
        uses: actions/download-artifact@d3f86a106a0bac45b974a628896c90dbdf5c8093 # v4.3.0
        with:
          path: downloaded-artifacts

      - name: Organize artifacts
        run: |
          set -euo pipefail

          mkdir -p binaries

          for artifact_dir in downloaded-artifacts/release-*/; do
            if [[ -d "$artifact_dir" ]]; then
              version=$(basename "$artifact_dir" | sed 's/release-//')
              echo "Processing version: $version"
              mkdir -p "binaries/${version}"
              cp -r "${artifact_dir}"* "binaries/${version}/" 2>/dev/null || true
            fi
          done

          echo "Final structure:"
          find binaries -type f | head -50

      - name: Configure Git
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"

      - name: Commit synced releases
        id: commit
        run: |
          set -euo pipefail

          if [[ -z "$(git status --porcelain binaries/)" ]]; then
            echo "No changes to commit"
            echo "has_changes=false" >> "$GITHUB_OUTPUT"
            exit 0
          fi

          git add binaries/
          git commit -m "chore: sync releases from R2 storage

          Synced versions: $(ls binaries/ | tr '\n' ', ' | sed 's/,$//')
          Triggered by: ${{ github.event_name }}
          Run ID: ${{ github.run_id }}"

          echo "has_changes=true" >> "$GITHUB_OUTPUT"

      - name: Push changes
        if: steps.commit.outputs.has_changes == 'true'
        run: git push origin HEAD
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Create GitHub Releases
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          VERSIONS_JSON: ${{ needs.prepare.outputs.versions_json }}
          FORCE_OVERWRITE: ${{ inputs.force_overwrite }}
        run: |
          set -euo pipefail

          echo "::group::Creating GitHub Releases"

          for VERSION in $(echo "$VERSIONS_JSON" | jq -r '.[]'); do
            RELEASE_DIR="binaries/${VERSION}"

            if [[ ! -d "$RELEASE_DIR" ]]; then
              echo "::warning::Release directory not found: $RELEASE_DIR"
              continue
            fi

            echo "Processing release: $VERSION"

            # Check if release exists
            if gh release view "$VERSION" &>/dev/null; then
              echo "  Release $VERSION already exists"

              if [[ "$FORCE_OVERWRITE" != "true" ]]; then
                echo "  Skipping (use force_overwrite to update)"
                continue
              fi

              echo "  Deleting existing release for overwrite..."
              gh release delete "$VERSION" --yes || true
              sleep 2
            fi

            # Collect release files (exclude manifest.json)
            FILES=()
            while IFS= read -r -d '' file; do
              FILES+=("$file")
            done < <(find "$RELEASE_DIR" -maxdepth 1 -type f ! -name "manifest.json" -print0)

            if [[ ${#FILES[@]} -eq 0 ]]; then
              echo "  ::warning::No files found for release $VERSION"
              continue
            fi

            echo "  Found ${#FILES[@]} files to upload"

            # Generate release notes
            RELEASE_NOTES="## Release $VERSION

          Automatically synchronized from R2 storage.

          ### Assets
          "
            if [[ -f "${RELEASE_DIR}/manifest.json" ]]; then
              RELEASE_NOTES+=$(jq -r '.assets[] | "- **\(.filename)** (\(.size_human)) - \(.platform)/\(.arch)"' "${RELEASE_DIR}/manifest.json" 2>/dev/null || echo "See attached files")
            fi

            # Determine if prerelease
            PRERELEASE_FLAG=""
            if [[ "$VERSION" =~ (alpha|beta|rc|dev|canary) ]]; then
              PRERELEASE_FLAG="--prerelease"
            fi

            # Create release
            echo "  Creating release..."
            if gh release create "$VERSION" \
              --title "Portless $VERSION" \
              --notes "$RELEASE_NOTES" \
              --draft=false \
              $PRERELEASE_FLAG \
              "${FILES[@]}"; then
              echo "  ✓ Created release $VERSION"
            else
              echo "  ::error::Failed to create release $VERSION"
            fi
          done

          echo "::endgroup::"

  # ============================================================================
  # Job 4: Update latest version reference
  # ============================================================================
  update-latest:
    name: Update Latest Reference
    needs: [prepare, publish]
    runs-on: ubuntu-22.04
    timeout-minutes: 5
    if: success() && inputs.dry_run != true && inputs.sync_all != true

    steps:
      - name: Update latest.json in R2
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
          R2_ENDPOINT_URL: ${{ secrets.R2_ENDPOINT_URL }}
          R2_BUCKET_NAME: ${{ secrets.R2_BUCKET_NAME }}
          R2_PUBLIC_URL: ${{ secrets.R2_PUBLIC_URL }}
          VERSION: ${{ needs.prepare.outputs.latest_version }}
        run: |
          set -euo pipefail

          if [[ -z "$VERSION" ]]; then
            echo "::error::No version specified"
            exit 1
          fi

          echo "Updating latest reference to: ${VERSION}"

          PUBLIC_URL="${R2_PUBLIC_URL:-}"

          # Generate latest.json
          cat > /tmp/latest.json << EOF
          {
            "version": "${VERSION}",
            "updated_at": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "download_urls": {
              "releases": "${PUBLIC_URL}/releases/${VERSION}",
              "binaries": "${PUBLIC_URL}/binaries/${VERSION}",
              "manifest": "${PUBLIC_URL}/releases/${VERSION}/manifest.json"
            },
            "github_release": "https://github.com/${{ github.repository }}/releases/tag/${VERSION}"
          }
          EOF

          echo "Latest metadata:"
          cat /tmp/latest.json

          # Upload to R2
          for DEST in "latest.json" "releases/latest.json"; do
            echo "Uploading to s3://${R2_BUCKET_NAME}/${DEST}..."
            aws s3 cp /tmp/latest.json "s3://${R2_BUCKET_NAME}/${DEST}" \
              --endpoint-url "${R2_ENDPOINT_URL}" \
              --region auto \
              --content-type "application/json" \
              --cache-control "max-age=300, s-maxage=60"
          done

          echo "✓ Latest reference updated to ${VERSION}"

  # ============================================================================
  # Job 5: Summary and notifications
  # ============================================================================
  summary:
    name: Workflow Summary
    needs: [prepare, sync, publish, update-latest]
    runs-on: ubuntu-22.04
    if: always()

    steps:
      - name: Generate Summary
        env:
          PREPARE_RESULT: ${{ needs.prepare.result }}
          SYNC_RESULT: ${{ needs.sync.result }}
          PUBLISH_RESULT: ${{ needs.publish.result }}
          UPDATE_RESULT: ${{ needs.update-latest.result }}
          VERSIONS_COUNT: ${{ needs.prepare.outputs.versions_count }}
          LATEST_VERSION: ${{ needs.prepare.outputs.latest_version }}
        run: |
          # Determine overall status
          if [[ "$PREPARE_RESULT" == "success" && "$SYNC_RESULT" == "success" ]]; then
            if [[ "${{ inputs.dry_run }}" == "true" ]]; then
              STATUS="✅ Dry Run Completed"
            elif [[ "$PUBLISH_RESULT" == "success" ]]; then
              STATUS="✅ Success"
            else
              STATUS="⚠️ Partial Success"
            fi
          elif [[ "$PREPARE_RESULT" == "success" && "$SYNC_RESULT" == "skipped" ]]; then
            STATUS="⏭️ Skipped (no versions to sync)"
          else
            STATUS="❌ Failed"
          fi

          cat >> $GITHUB_STEP_SUMMARY << EOF
          # Release Sync Summary

          **Status:** ${STATUS}
          **Triggered by:** ${{ github.event_name }}
          **Run ID:** [${{ github.run_id }}](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})

          ## Configuration
          | Setting | Value |
          |---------|-------|
          | Dry Run | ${{ inputs.dry_run || 'false' }} |
          | Sync All | ${{ inputs.sync_all || 'false' }} |
          | Force Overwrite | ${{ inputs.force_overwrite || 'false' }} |
          | Input Version | ${{ inputs.version || '(latest)' }} |

          ## Results
          | Job | Status |
          |-----|--------|
          | Prepare | ${PREPARE_RESULT} |
          | Sync | ${SYNC_RESULT} |
          | Publish | ${PUBLISH_RESULT:-skipped} |
          | Update Latest | ${UPDATE_RESULT:-skipped} |

          ## Versions
          - **Count:** ${VERSIONS_COUNT:-0}
          - **Latest:** ${LATEST_VERSION:-N/A}

          ---
          *Completed at $(date -u +%Y-%m-%dT%H:%M:%SZ)*
          EOF

      - name: Notify on failure
        if: failure()
        run: |
          echo "::error::Release sync workflow failed. Check the logs for details."
